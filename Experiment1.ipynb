{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta75FnTqz6_u"
   },
   "source": [
    "\n",
    "This notebook is used to test two different deep neural networks on one datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15588,
     "status": "ok",
     "timestamp": 1725568081134,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "vMt5Yw6Mc-Ol",
    "outputId": "d29fba3c-7042-4327-face-165007962319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: numpy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: torch==2.4.1+cu124 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (2.4.1+cu124)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch==2.4.1+cu124->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch==2.4.1+cu124->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch==2.4.1+cu124->torchvision) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yibor\\appdata\\local\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "#install the necessary modules\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1725569880014,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "AMMntrpMzzom"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1725568122446,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "dcZdY0Hn34k2"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  ,\n",
    "    # transforms.RandomRotation(10),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1725569969469,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "afwySqEp4N1O",
    "outputId": "d33f7b05-fde6-43fc-c8a8-648e470ee876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "3000\n",
      "57000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The MNIST dataset is divided into two main folders: one for training and one for testing. To further improve the model's evaluation, \n",
    "I will create a validation set by extracting 5% of the training data. \n",
    "This validation set will allow me to assess the model's accuracy during training without using the test set. \n",
    "By validating on data the model has never encountered, I can better determine if the model is overfitting, ensuring a more generalizable performance.\n",
    "        Validation set size: 3,000\n",
    "        Test set size: 10,000\n",
    "        Training set size: 57,000\n",
    "\"\"\"\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Function to split the dataset\n",
    "def dataset_split(train_dataset, val_ratio=0.05):\n",
    "    # Calculate validation size based on the ratio\n",
    "    val_size = int(len(train_dataset) * val_ratio)\n",
    "    train_size = len(train_dataset) - val_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    return val_loader, train_loader\n",
    "\n",
    "val_loader, train_loader = dataset_split(train_dataset, val_ratio=0.05)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1725572751512,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "KwvEkNuR2Lg0"
   },
   "outputs": [],
   "source": [
    "class NetworkA(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NetworkA, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(784,64)\n",
    "    self.fc2 = nn.Linear(64,128)\n",
    "    self.fc3 = nn.Linear(128,64)\n",
    "    self.fc4 = nn.Linear(64,10)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "  def forward(self,x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    x = self.relu(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1725572581851,
     "user": {
      "displayName": "yassine Ibork",
      "userId": "01838310555327163178"
     },
     "user_tz": 300
    },
    "id": "Ook17qz0ES6l"
   },
   "outputs": [],
   "source": [
    "class NetworkB(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NetworkB, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(784,256)\n",
    "    self.fc2 = nn.Linear(256,512)\n",
    "    self.fc3 = nn.Linear(512,128)\n",
    "    self.fc4 = nn.Linear(128,10)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "  def forward(self,x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    x = self.relu(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61QQDe840QYv"
   },
   "source": [
    "[link text](https://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = [None, None]\n",
    "models[0] = NetworkA().to(device)\n",
    "models[1] = NetworkB().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader,num_epochs): \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    # To store training data for plotting\n",
    "    training_data = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_error': [],\n",
    "        'test_error': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "        train_error = 1 - (correct_train / total_train)\n",
    "\n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                total_test_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader.dataset)\n",
    "        test_error = 1 - (correct_test / total_test)\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        # Store metrics\n",
    "        training_data['train_loss'].append(avg_train_loss)\n",
    "        training_data['test_loss'].append(avg_test_loss)\n",
    "        training_data['train_error'].append(train_error)\n",
    "        training_data['test_error'].append(test_error)\n",
    "        training_data['accuracy'].append(accuracy)\n",
    "        training_data['precision'].append(precision)\n",
    "        training_data['recall'].append(recall)\n",
    "        training_data['f1_score'].append(f1)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, '\n",
    "              f'Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    training_data['training_time'] = training_time\n",
    "\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_results(model, model_name, training_data):\n",
    "    torch.save(model.state_dict(), f'{model_name}_model.pth')\n",
    "    # Convert training data to a JSON-serializable format\n",
    "    serializable_data = {}\n",
    "    for key, value in training_data.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            serializable_data[key] = value.tolist()  # Convert Tensors to lists\n",
    "        elif isinstance(value, list) and isinstance(value[0], torch.Tensor):\n",
    "            serializable_data[key] = [v.tolist() for v in value]  # Convert lists of Tensors\n",
    "        else:\n",
    "            serializable_data[key] = value\n",
    "\n",
    "    # Save the training data as JSON\n",
    "    with open(f'{model_name}_training_data.json', 'w') as json_file:\n",
    "        json.dump(serializable_data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1: NetworkA(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training model 2: NetworkB(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate(models):\n",
    "    print(f'Training model {idx + 1}: {model}')\n",
    "    training_data = train_and_evaluate(model, train_loader, test_loader, num_epochs=500)\n",
    "\n",
    "    save_model_and_results(model, f'model_{idx + 1}', training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Network1 on the whole validation set: 97.67%\n",
      "Accuracy for Network2 on the whole validation set: 98.13%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Loop through both models to evaluate them on the whole validation set\n",
    "for i, model in enumerate(models):\n",
    "    accuracy = evaluate_model(model, val_loader)\n",
    "    print(f'Accuracy for Network{i+1} on the whole validation set: {accuracy:.2%}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIDTvxa7B1irZDHIQLXrAb",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
